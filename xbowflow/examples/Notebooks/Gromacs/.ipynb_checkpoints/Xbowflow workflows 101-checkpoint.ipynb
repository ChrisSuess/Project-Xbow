{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An introduction to xbowflow workflows\n",
    "\n",
    "In this notebook you will see how a simple MD simulation job can be converted from its normal command-line form into a Python function using tools in *Xbowflow*.\n",
    "\n",
    "Then you will see how it's easy to chain jobs together to create a workflow.\n",
    "\n",
    "The notebook assumes you have a basic knowledge of *Gromacs*, and that *Gromacs* is installed on the computer you are running this notebook on.\n",
    "\n",
    "Some knowledge of the Python package *MDTraj* may also help, but is not obligatory.\n",
    "\n",
    "----\n",
    "\n",
    "### Part 1: running jobs the conventional way\n",
    "Have a look at the contents of this directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see:\n",
    "\n",
    "    Xbowflow workflows 101.ipynb : This notebook\n",
    "    bpti.gro                     : Coordinates for BPTI in Gromacs .gro format\n",
    "    bpti.top                     : Gromacs topology file for BPTI\n",
    "    em.mdp                       : A Gromacs .mdp file defining an energy minimisation job\n",
    "    nvt.mdp                      : a Gromacs .mdp file defining a short NVT MD simulation\n",
    "    \n",
    "Let's begin by running the energy minimisation job interactively in the conventional way. \n",
    "\n",
    "First we run grompp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gmx grompp -f em.mdp -c bpti.gro -p bpti.top -o bpti-em.tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming everything there went as expected, now we can run the energy minimisation itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gmx mdrun -s bpti-em.tpr -c bpti-em.gro -g bpti-em.log -o bpti-em.trr -e bpti-em.edr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the job completed without errors, you should see the output files in the current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the log file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat bpti-em.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Turning this into Python\n",
    "\n",
    "OK. Now you will see how you can turn the energy minimisation job from something you run on the command line (in this situation, within a Jupyter notebook, by using the \"!\" special command) into a pure Python function.\n",
    "\n",
    "The function will take a .tpr file as the input, and return the .gro and .log files when the job completes. For now, you can assume you are not that bothered about what's in the .edr and .trr files.\n",
    "\n",
    "So your aim is something like this:\n",
    "\n",
    "    grofile, logfile = mdrun(tprfile)\n",
    "    \n",
    "---\n",
    "\n",
    "Begin by importing the *xflowlib* module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbowflow import xflowlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you create the function, which in xflowlib is called a **Kernel**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = xflowlib.SubprocessKernel('gmx mdrun -s {x.tpr} -c {x.gro} -g {x.log} -e {x.edr} -o {x.trr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that creating the function (or \"kernel\") involves providing a \"template\" for the command you want to run. The names of the files in the template are completely up to you (e.g. you could use \"system.tpr\", etc. instead of \"x.tpr\") - but in general make sure the filenames have the appropriate extensions.\n",
    "\n",
    "---\n",
    "\n",
    "Now you have to tell the kernel what files are inputs, and what are outputs. To do this you pass *lists* of strings that correspond to the filenames in the template above. \n",
    "\n",
    "**NB:** the order of the strings in the inputs list defines the order that input variables will be passed to the kernel, and the order of the strings in the output list defines the order that the outputs from the function will appear in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the kernel the signature: grofile, logfile = mdrun.run(tprfile)\n",
    "md.set_inputs(['x.tpr'])\n",
    "md.set_outputs(['x.gro', 'x.log'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's about it - your new function is ready for use.\n",
    "\n",
    "However, your data is not quite ready. Xbowflow is designed to work with distributed computing facilities that may not share a common file system. So before you can use the function, you need to get the input .tpr file into a suitable globally-accessible variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xflowlib.set_filehandler('memory')\n",
    "tprfile = xflowlib.load('bpti-em.tpr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run the function, by caling its run() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grofile, logfile = md.run(tprfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can look at the results, you need to convert the globally-accessible output variables back into files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile.save('test.log')\n",
    "grofile.save('test.gro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat test.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat test.gro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened to the information that gets written to the screen when you run the job via the command line? It's captured in the STDOUT attribute of the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(md.STDOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: A workflow\n",
    "\n",
    "Let's make a workflow that runs a grompp job, then immediately the md (or energy minimisation) job.\n",
    "\n",
    "You already have a kernel that can run *mdrun*, but you need to build one to run *grompp*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a kernel with the signature: tprfile = grompp.run(mdpfile, grofile, topfile):\n",
    "grompp = xflowlib.SubprocessKernel('gmx grompp -f {x.mdp} -c {x.gro} -p {x.top} -o {x.tpr} -maxwarn 1')\n",
    "grompp.set_inputs(['x.mdp', 'x.gro', 'x.top'])\n",
    "grompp.set_outputs(['x.tpr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables from the required input files:\n",
    "emfile = xflowlib.load('em.mdp')\n",
    "start_crds = xflowlib.load('bpti.gro')\n",
    "topfile = xflowlib.load('bpti.top')\n",
    "# Run the job:\n",
    "em_tprfile = grompp.run(emfile, start_crds, topfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from this kernel should be ready for use in the mdrun kernel - let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For clarity, re-run the grompp job:\n",
    "em_tprfile = grompp.run(emfile, start_crds, topfile)\n",
    "# Now the energy minimisation:\n",
    "em_crds, em_logfile = md.run(em_tprfile)\n",
    "\n",
    "em_logfile.save('em.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat em.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Exercise - a bigger workflow\n",
    "\n",
    "Your turn - add the second simulation stage - the NVT MD - into your workflow.\n",
    "\n",
    "Hints:\n",
    "    1. You don't need to make any new kernels - re-use the ones you have.\n",
    "    2. Don't forget that you will need to create a variable from the file nvt.mdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A workflow that runs an energy minimisation and then an NVT MD simulation\n",
    "# For clarity, start at the beginning:\n",
    "em_tprfile = grompp.run(emfile, start_crds, topfile)\n",
    "em_crds, em_logfile = md.run(em_tprfile)\n",
    "# Add your code below:\n",
    "nvtfile = xflowlib.load('nvt.mdp')\n",
    "nvt_tprfile = grompp.run(nvtfile, em_crds, topfile)\n",
    "nvt_crds, nvt_logfile = md.run(nvt_tprfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: A better workflow\n",
    "\n",
    "Let's improve the workflow. Firstly, it would be nice if the NVT simulation job also returned the trajectory file. You don't want this for the EM job, so what that means is that you need to make a second mdrun-type kernel. Here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_with_traj = md.copy()\n",
    "md_with_traj.set_outputs(['x.gro', 'x.log', 'x.trr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The copy() convenience method saves you having to rewrite the kernel from scratch, if  it's just a tweak on an existing one.\n",
    "\n",
    "Next, notice that both grompp jobs in the workflow above take the same topology file as an argument - in effect, it's a constant. In such cases, you can define it as such at the time you create the kernel, and then you don't have to include it in the list of arguments when you call it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grompp.set_constant('x.top', topfile)\n",
    "# Now the new improved workflow:\n",
    "em_tprfile = grompp.run(emfile, start_crds)\n",
    "em_crds, em_logfile = md.run(em_tprfile)\n",
    "nvt_tprfile = grompp.run(nvtfile, em_crds)\n",
    "nvt_crds, nvt_logfile, nvt_traj = md_with_traj.run(nvt_tprfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: interfacing with more Python\n",
    "\n",
    "At this stage you may be thinking \"OK - but nothing here I couldn't do with a bash script\". The power of the workflow comes when you interface your new pythonized-MD functions with other Python tools.\n",
    "\n",
    "Let's make use of the *MDTraj* package for analysis of MD trajectory data. You will use it to calculate the RMSD of the trajectory frames from the starting structure.\n",
    "\n",
    "If you are not yet familiar with MDTraj don't worry - what's below should be more or less self-explanatory.\n",
    "\n",
    "The MDTraj load() method expects conventional  *filenames* as arguments. For this, you can use the as_file() method of a variable created by xbowflow.load():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as mdt\n",
    "traj = mdt.load(nvt_traj.as_file(), top=start_crds.as_file())\n",
    "print(traj)\n",
    "# Calculate the rmsd of each frame from the first:\n",
    "print(mdt.rmsd(traj, traj[0], atom_indices=traj.topology.select('protein')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make your workflow identify which snapshot from your trajectory has the highest RMSD from the starting structure, and then energy minimise that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rmsdlist = mdt.rmsd(traj, traj[0], atom_indices=traj.topology.select('protein'))\n",
    "i = np.argmax(rmsdlist)\n",
    "print('Energy minimising snapshot {}'.format(i))\n",
    "em2_tprfile = grompp.run(emfile, traj[i])\n",
    "em2_crds, em2_logfile = md.run(em2_tprfile)\n",
    "em2_crds.save('max_rmsd.gro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7: Final exercise\n",
    "\n",
    "Create a Python function that in effect does all the above: takes a set of starting coordinates, a topology file, and two .mdp files (one for an energy minimisation, one for an MD run), runs the workflow and then returns the energy-minimised structure of the snapshot with the highest RMSD from the starting structure. The function should do everything, including creating the required kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_workflow(crd_filename, top_filename, em_mdp_filename, md_mdp_filename):\n",
    "    # Over to you!\n",
    "    # Load data:\n",
    "    start_crds = xflowlib.load(crd_filename)\n",
    "    topfile = xflowlib.load(top_filename)\n",
    "    emfile = xflowlib.load(em_mdp_filename)\n",
    "    mdfile = xflowlib.load(md_mdp_filename)\n",
    "    \n",
    "    # Create kernels:\n",
    "    grompp = xflowlib.SubprocessKernel('gmx grompp -f {x.mdp} -c {x.gro} -p {x.top} -o {x.tpr} -maxwarn 1')\n",
    "    grompp.set_inputs(['x.mdp', 'x.gro'])\n",
    "    grompp.set_constant('x.top', topfile)\n",
    "    grompp.set_outputs(['x.tpr'])\n",
    "    \n",
    "    md = xflowlib.SubprocessKernel('gmx mdrun -s {x.tpr} -c {x.gro} -g {x.log} -e {x.edr} -o {x.trr}')\n",
    "    md.set_inputs(['x.tpr'])\n",
    "    md.set_outputs(['x.gro', 'x.log'])\n",
    "    \n",
    "    md_with_traj = md.copy()\n",
    "    md_with_traj.set_outputs(['x.gro', 'x.log', 'x.trr'])\n",
    "    \n",
    "    # Run workflow:\n",
    "    em_crds, em_logfile = md.run(grompp.run(emfile, start_crds))\n",
    "    md_crds, md_logfile, md_traj = md_with_traj.run(grompp.run(mdfile, em_crds))\n",
    "    traj = mdt.load(md_traj.as_file(), top=start_crds.as_file())\n",
    "    rmsdlist = mdt.rmsd(traj, traj[0], atom_indices=traj.topology.select('protein'))\n",
    "    i = np.argmax(rmsdlist)\n",
    "    print('Energy minimising snapshot {}'.format(i))\n",
    "    em2_crds, em2_logfile = md.run(grompp.run(emfile, traj[i]))\n",
    "    \n",
    "    # Return final structure:\n",
    "    return em2_crds\n",
    "\n",
    "# Test the workflow:\n",
    "final_crds = my_workflow('bpti.gro', 'bpti.top', 'em.mdp', 'nvt.mdp')\n",
    "final_crds.save('final_coordinates.gro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
